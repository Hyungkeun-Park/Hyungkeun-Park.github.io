---
title: "[PRML] 패턴인식과 머신 러닝 Ch1. 소개 - 확률론(2)"
#excerpt: ""

toc: true
toc_sticky: true

use_math: true

categories:
    - PRML
tags:
    - Deep Learning
    - Machine Learning
last_modified_at: 2023-07-11T16:00:00
---

작성중
{: .notice}

> 패턴 인식 분야에서 중요한 콘셉트 중 하나는 바로 '불확실성'이다<br>
확률론은 불확실성을 계량화하고 조작하기 위한 이론적 토대를 마련해준다

우선 책의 예시를 따라가며 확률론에 대해 스윽 한 번 공부해보고자 한다<br>
<br>

# 확률 예시
* * *
![image](https://github.com/Hyungkeun-Park/Hyungkeun-Park.github.io/assets/21329629/0a4604d1-813f-4728-a781-70d6d1da8c60){: .align-center, width="50%", height="50%" }
<br>
<br>
한 개의 빨간색 상자와 한 개의 파란색 상자가 놓여 있고<br>
빨간 상자 안에는 두 개의 사과(초록)와 여섯 개의 오렌지(주황)가<br>
파란 상자 안에는 세 개의 사과와 한 개의 오렌지가 있다고 하자<br>
<br>
상자를 확률 변수 $B$로 정하고, 이 확률 변수 $B$는 $r(빨강)$과 $b(파랑)$ 두 개의 값을 가질 수 있다<br>
과일 역시 확률 변수 $F$로 정하고, $F$는 $a(사과)$와 $o(오렌지)$를 값으로 가질 수 있다<br>
<br>
확률의 정의에 따라서 확률값은 [0,1] 구간 안에 있어야 하고<br>
각각의 사건들이 모든 결과를 포함한 경우 확률들의 합은 1이다<br>
빨간색 박스를 고를 확률을 40%, 파란색 박스를 고를 확률을 60%라고 할 때<br>
<br>
> $p(B=r)=0.4,\;  p(B=b)=0.6$로 확률 변수 B에 대한 확률을 표현할 수 있으며<br>
$p(B=r)+p(B=b)=0.4+0.6=1$를 통해 박스를 고르는 사건에 대한 확률의 합이 1임을 알 수 있다<br>
<br>

>만약 우리가 빨간 상자를 선택했을 때 사과를 고를 확률은<br>
$p(F=a|B=r)=1/4$라고 쓸 수 있는데, 이와 같은 확률을 `조건부확률`이라고 한다<br>

